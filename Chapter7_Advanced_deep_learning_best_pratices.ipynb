{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<< [第六章：文本和序列的深度学习](Chapter6_Deep_learning_for_text_and_sequences.ipynb)|| [目录](index.md) || [第八章：生成模型深度学习](Chapter8_Generative_deep_learning.ipynb) >>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第七章：高级深度学习最佳实践\n",
    "\n",
    "> In this chapter, we cover more advanced techniques for designing and manipulating deep\n",
    "neural networks:\n",
    "\n",
    "> -The Keras functional API, with which you will be able to build graph-like models, share\n",
    "a same layer across different inputs, and use Keras models just like Python functions.\n",
    "- Keras callbacks, and the TensorBoard browser-based visualization tool, to monitor\n",
    "models during training.\n",
    "- Important best practices such as batch normalization, residual connections,\n",
    "hyperparameter optimization, and model ensembling.\n",
    "\n",
    "在本章中，我们会介绍更多设计和操作深度神经网络的高级技巧：\n",
    "\n",
    "- Keras的函数API，它们允许你能够构建图神经模型，在多个输入中共享相同的层，然后就像使用Python函数那样使用Keras模型。\n",
    "- Keras回调，以及TensorBoard的Web可视化工具，来监控模型训练过程。\n",
    "- 一些重要的最佳实践包括批归一化，残差连接，超参数优化和模型组装。\n",
    "\n",
    "> These are powerful tools that will bring you closer to being able to develop\n",
    "state-of-art models on difficult problems.\n",
    "\n",
    "这些强大的工具可以让你能够在困难问题上从细节开始设计开发更加先进的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 超越序列模型：使用Keras函数API\n",
    "\n",
    "> Until now, all neural networks introduced in this book have been implemented using the\n",
    "Sequential model. The Sequential model makes the assumption that the network has\n",
    "exactly one input and exactly one output, and that it consists of a linear stack of layers.\n",
    "\n",
    "直到目前，本书介绍的所有神经网络都是使用序列模型构建的。这种模型假设你的网络正好只有一个输入和一个输出，因此它只包含线性堆叠的层。\n",
    "\n",
    "![sequential model](imgs/f7.1.jpg)\n",
    "\n",
    "图7-1 序列模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is a very commonly verified assumption; this configuration is in fact so common\n",
    "that we have been able to cover many topics and practical applications in these pages so\n",
    "far using only the Sequential model class. However, this set of assumptions is too\n",
    "inflexible in a number of cases. Some networks require several independent inputs, some\n",
    "others require multiple outputs, and some networks have internal branching between\n",
    "layers making them look like graphs of layers rather than linear stacks of layers.\n",
    "\n",
    "这是一个非常普遍并经过验证的假设：这样的配置事实上是如此的普遍，我们仅使用序列模型就能覆盖许多的主题和实际应用。然而，这样的假设在一些场景中就显得不够灵活了。一些网络需要多个独立的输入，其他一些需要多个输出，还有一些网络在层次之间会存在分支，使得它们看起来更像一张图，而不是层次的线性堆叠。\n",
    "\n",
    "> Some tasks, for instance, require multi-modal inputs: they merge data coming from\n",
    "different input sources, processing each type of data using different kinds of neural\n",
    "layers. Imagine a deep learning model trying to predict the most likely market price of a\n",
    "second-hand piece of clothing, using as input: 1) some user-provided metadata (such as\n",
    "the brand, the age, etc.), 2) a user-provided text description, and 3) a picture of the item.\n",
    "If we only had the metadata available, we could one-hot encode it and use a\n",
    "densely-connected network to predict the price. If we only had the text description\n",
    "available, we could use a RNN or a 1D convnet. If we only had the picture, we could use\n",
    "a 2D convnet. But how can all leverage all three at the same time? A naive approach\n",
    "would be to train three separate models, and then do a weighted average of their\n",
    "predictions. However, this may well be suboptimal, because the information extracted by\n",
    "the models may be high redundant. A better way is to jointly learn a more accurate model\n",
    "of the data by using a model that can see all available input modalities simultaneously: a\n",
    "model with three input branches (see Figure 7.2).\n",
    "\n",
    "比如说有一些任务需要多模态输入：它们从不同的输入源中合并数据，使用不同类型的神经层来处理每种数据。设想一个深度学习模型试图预测二手衣物的可能市场价格，可能使用这些输入：1）一些用户提供的元数据（如品牌，使用时间等），2）一个用户提供的文本描述以及3）物品的照片。如果我们仅仅有元数据的话，我们可以使用one-hot对其进行编码然后使用一个全连接网络来预测价格。如果我们仅仅有文字描述数据的话，我们可以使用一个RNN或1D卷积网络。如果我们仅仅有照片数据的话，我们可以使用一个2D卷积网络。但是如果能够在一个网络中同时平衡三种输入数据呢？有一种原始的解决办法，分别训练三个独立的模型，然后将它们输出的预测值进行加权平均。但是这个方法是非常低效的，因为从每个模型中提取到的信息可能是高度冗余的。一个更好的方法是使用一个能够同时观察所有的输入数据，并联合进行学习：也就是一个具有三个输入分支的模型（参见图7-2）。\n",
    "\n",
    "![multi-input model](imgs/f7.2.jpg)\n",
    "\n",
    "图7-2 一个具有多个输入的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Similarly, some tasks require predicting multiple target attributes of some input data.\n",
    "Given the text of a novel or short-story, one might want to automatically classify it by\n",
    "genre (e.g. romance, thriller) but also predict the approximate date it was written. Of\n",
    "course, one could simply train two separate models, one for the genre and one for the\n",
    "date. However, because these attributes are not statistically independent, we can build a\n",
    "better model by learning to jointly predict both genre and date at the same time. Such a\n",
    "joint model would then have two outputs, or two \"heads\" (Figure 7.3). Due to\n",
    "correlations between genre and date, knowing the date of a novel will help the model\n",
    "learn rich and accurate representations of the space of novel genres, and reciprocally.\n",
    "\n",
    "类似的，有些任务需要对一些输入数据预测多个目标属性。给定小说或者短片故事的文本，一个任务可能需要将它们自动分类（如爱情、惊恐），还需要预测它们写成的年代。当然，你也可以简单的训练两个独立模型来处理，一个分类一个预测年代。但是因为这些属性并不是统计学独立的，所以我们可以构建一个更好的模型，同时训练两个目标。这样的联合模型就具有两个不同的输出，或者叫做两个“头”（图7-3）。由于分类和年份直接的互相关联，知道了小说写成的年代能够帮助模型获得更加丰富和准确的分类空间信息，反之亦然。\n",
    "\n",
    "![multi-output model](imgs/f7.3.jpg)\n",
    "\n",
    "图7-3 一个具有多输出（多头）的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Additionally, many recent neural architectures require non-linear network topology:\n",
    "networks structured as directed acyclic graphs. The Inception family of networks\n",
    "(developed by Szegedy et al. at Google), for instance, relies on \"Inception modules\",\n",
    "where the input is processed by several parallel convolutional branches whose outputs\n",
    "then get merged back into a single tensor (Figure 7.4). There is also the recent trend of\n",
    "adding \"residual connections\" to a model, which started with the ResNet family of\n",
    "networks (developed by He et al at Microsoft). A residual connection consists simply in\n",
    "reinjecting previous representations into the downstream flow of data, by adding a past\n",
    "output tensor to later output tensor (Figure 7.5), which helps prevent information loss\n",
    "along the data processing flow. And there are many more examples of such graph-like\n",
    "networks.\n",
    "\n",
    "还有就是进来很多神经网络结构需要非线性网络拓扑：网络具有有向无环图结构。例如神经网络中的感知家族（由Google的Szegedy发明的），依赖其中的“感知模块”，会将输入处理成多个并行的卷积分支，它们的输出之后会被重新合并到一个张量中（图7-4）。最近也有一个趋势需要在模型中增加“残差连接”，广泛应用在神经网络中的ResNet家族（由微软的He发明的）。一个具有残差连接的模型可以简单地将之前的表现形式再次诸如到下游的数据流中，通过将之前的输出张量加入到后续的输出张量当中（图7-5），可以避免在数据处理流中产生信息损失。除此之外，还有很多其他的图神经网络的形式。\n",
    "\n",
    "![inception module](imgs/f7.4.jpg)\n",
    "\n",
    "图7-4 感知模块：由多个并行卷积层分支组成的图网络结构\n",
    "\n",
    "![residual connections](imgs/f7.5.jpg)\n",
    "\n",
    "图7-5 残差连接：通过特征地图相加将之前输出数据再次注入下游数据中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> These three important use cases—multi-input models, multi-output models, and\n",
    "graph-like models—are not possible when using only the Sequential model class in\n",
    "Keras. But there is also a different, far more general and flexible way to use Keras: the\n",
    "functional API . This sections explains in detail what it is, what it can do, and how to use\n",
    "it.\n",
    "\n",
    "这三种重要的应用场景：多输入模型，多输出模型和图网络模型，在使用Keras的序列模型的情况下都是无法实现的。不过Keras还提供了一个不同的，但更加通用和灵活的方法来满足这些场景：函数API。这个小节会详细介绍它是什么，它能做什么和如何使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 函数API介绍\n",
    "\n",
    "> In the functional API, you are directly manipulating tensors, and you use layers as\n",
    "functions that take tensors and return tensors (hence the name \"functional API\").\n",
    "\n",
    "在函数API中，你将要直接操纵张量，模型的层会当成函数一样来使用，接受张量和返回张量（因此命名为“函数API”）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, layers\n",
    "\n",
    "# 定义一个张量\n",
    "input_tensor = Input(shape=(32,))\n",
    "\n",
    "# 一个网络层就是一个函数\n",
    "dense = layers.Dense(32, activation='relu')\n",
    "\n",
    "# 层次可以使用张量来调用，并返回一个张量\n",
    "output_tensor = dense(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let’s start with a minimal example: we will show side by side a simple Sequential\n",
    "model and its equivalent in the functional API.\n",
    "\n",
    "让我们从一个最简单的例子开始：我们展示一个简单的序列模型和它对等的函数API模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers, Input\n",
    "\n",
    "# 下面是一个序列模型，你应该已经完全了解了\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 下面是与其对等的函数API模型\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# 使用Model类将输入张量和输出张量转换成一个模型\n",
    "model = Model(input_tensor, output_tensor)\n",
    "\n",
    "# 看一下模型的情况\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The only part that may seem a bit magical at this point is instantiating a Model object\n",
    "using only an input tensor and output tensor. Behind the scenes, Keras will retrieve every\n",
    "layer that was involved in going from input_tensor to output_tensor , bringing them\n",
    "together into a graph-like data structure—a Model . Of course, the reason it works is\n",
    "because output_tensor was indeed obtained by repeatedly transforming input_tensor\n",
    ". If you tried to build a model from inputs and outputs that were not related, you would\n",
    "get a RuntimeError :\n",
    "\n",
    "上面的代码中唯一看起来有点像魔术的就是使用输入张量和输出张量来初始化模型对象部分。在实现中，Keras会获取每一个涉及从输入张量计算得到输出张量需要用到的层次，将它们组合在一起构建一个图网络数据结构，也就是模型。当然，这能够实现的原因是输出张量确实能够通过输入张量经过有限次的计算后得到。如果你尝试构建一个模型，其输入和输出是不相关的，就会得到一个RuntimeError：\n",
    "\n",
    "译者注：新版的Keras将错误改成了ValueError。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"input_2:0\", shape=(None, 64), dtype=float32) at layer \"input_2\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b18fa274e6fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0munrelated_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbad_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munrelated_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# initializing _distribution_strategy here since it is possible to call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m    168\u001b[0m       \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0;32m--> 324\u001b[0;31m         self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    325\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1674\u001b[0m                              \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m                              \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m                              str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1677\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m           \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_2:0\", shape=(None, 64), dtype=float32) at layer \"input_2\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "unrelated_input = Input(shape=(32,))\n",
    "bad_model = Model(unrelated_input, output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This error tells you, in essence, that Keras was not able to reach input_1 from the\n",
    "provided output tensor.\n",
    "\n",
    "这个错误告诉你，Keras无法从input_2获取能够到达输出张量的路径。\n",
    "\n",
    "> When it comes to compiling, training or evaluating such an instance of Model , the\n",
    "API is the same as that of Sequential :\n",
    "\n",
    "当对这样的模型进行编译、训练和评估时，使用的是与序列模型相同的API："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 352us/sample - loss: 11.9589\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 13us/sample - loss: 12.6993\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 14.2038\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 28us/sample - loss: 15.9779\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 14us/sample - loss: 17.5353\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 19.7986\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 12us/sample - loss: 22.6058\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 24us/sample - loss: 26.4214\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 22us/sample - loss: 30.4819\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 9us/sample - loss: 35.1275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa1c86aba20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 编译模型\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# 创建一个随机Numpy张量来进行训练\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 103us/sample - loss: 37.9977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37.997671295166015"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 评估模型\n",
    "model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2 多输入模型\n",
    "\n",
    "> The functional API can be used to build models that have multiple inputs. Typically, such\n",
    "models will at some point \"merge\" their different input branches using a layer that can\n",
    "combine several tensors, i.e. by adding them, concatenating them, etc. This is usually\n",
    "done via a Keras \"merge operation\" such as keras.layers.add ,\n",
    "keras.layers.concatenate , etc. Let’s take a look at a very simple example of a\n",
    "multi-input model: a question-answering model.\n",
    "\n",
    "上面介绍的函数API可以用来构建具有多个输入的模型。特别是这样的模型会在某个点“合并”它们不同的输入分支，这里使用了一种能够组合多个张量的层，实际上就是将这些张量相加或者级联等。这个层次通常使用Keras的“合并操作”或“级联操作”完成，也就是keras.layers.add或者keras.layers.concatenate等函数。下面让我们看一个非常简单的多输入模型例子：回答问题模型。\n",
    "\n",
    "> A typical question-answering model has two inputs: a natural language question, and\n",
    "a text snippet (such as a news article) providing information to be used for answering the\n",
    "question. The model must then produce an answer: in the simplest possible setup, this is\n",
    "simply a one-word answer obtained via a softmax over some predefined vocabulary. This\n",
    "is presented in Figure 7.6.\n",
    "\n",
    "一个典型的问答模型有两个输入：一个自然语言的问题，和一个文本片段（例如一篇新的文章）提供了用来回答问题的信息。这个模型然后输出一个回答：在最简单的配置中，这就是一个单词的回答，使用softmax在一些预定义的词汇表中选取得到。正如图7-6所示。\n",
    "\n",
    "![question-answer model](imgs/f7.6.jpg)\n",
    "\n",
    "图7-6 一个问答模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here is an example of how we can build such a model with the functional API: we set\n",
    "up two independent branches, encoding the text input and the question input as\n",
    "representation vectors, then we concatenate these vectors, and finally, we add a softmax\n",
    "classifier on top of the concatenated representations.\n",
    "\n",
    "下面是一个例子，展示我们使用函数API来构建这样的模型：我们构建两个独立的分支，将输入的参考文本和问题编码成向量，然后将这些向量级联起来，最后我们使用一个softmax分类器来获得最终的输出结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, Input\n",
    "\n",
    "text_vocabulary_size = 10_000\n",
    "question_vocabulary_size = 10_000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# 这里的参考文本输入是一段可变长度的文字，我们还可以为输入张量命名\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "\n",
    "# 我们将文本嵌入到一个形状为64的向量中\n",
    "embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)\n",
    "\n",
    "# 然后我们将它通过LSTM编码成一个独立向量\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "# 下面按照同样的方法处理问题文本\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(32, question_vocabulary_size)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "# 然后将两个输入得到的输出张量级联\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "# 最顶层是一个全连接层，使用softmax激活，得到答案\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "# 初始化模型实例时，我们使用两个输入和一个输出\n",
    "model = Model([text_input, question_input], answer)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, how do we train this two-input model? There are two possible APIs: you could\n",
    "feed as inputs to the model a list of Numpy arrays, or you could feed it a dictionary\n",
    "mapping input names to Numpy arrays. Naturally, the latter option is only available if\n",
    "you gave names to your inputs.\n",
    "\n",
    "下面，我们应该如何训练这个双输入的模型呢？这里有两种可用的API：你可以将一个Numpy数组的列表作为输入给模型，或者你可以将一个输入名称和Numpy数组值的字典作为输入给模型。当然后一种方式仅在你指定了输入名称的情况下有效。\n",
    "\n",
    "译者注：以下代码在tensorflow 2上无法运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "# 我们构建一些随机Numpy数组来训练模型\n",
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
    "\n",
    "# 答案是one-hot编码的，不是整数\n",
    "answer = np.random.randint(0, 1, size=(num_samples, answer_vocabulary_size))\n",
    "\n",
    "# 使用Numpy数组列表代入\n",
    "model.fit([text, question], answer, epochs=10, batch_size=32)\n",
    "\n",
    "# 使用字典代入，仅在设定了输入名称时有效\n",
    "model.fit({'text': text, 'question': question}, answer, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3 多输出模型\n",
    "\n",
    "> In the same way, the functional API can be used to build models with multiple outputs\n",
    "(or multiple \"heads\", as sometimes described in the literature). A simple example would\n",
    "be a network that attempts to simultaneously predict different properties of the data: let’s\n",
    "say, a network that takes as input a series of social media posts from one single\n",
    "anonymous person, and tries to predict attributes of that person, such as age, gender, or\n",
    "income level (Figure 7.7).\n",
    "\n",
    "同样的可以使用函数API来构建具有多个输出（在一些文献中也叫做多个“头”）的模型。一个简单的例子是模型可能需要同时预测数据集的多个不同的特征：比如一个接受某个匿名用户的社交媒体数据的网络，并尝试从这些数据当中预测该用户的年龄、性别或者收入情况。\n",
    "\n",
    "![multi-output network](imgs/f7.7.jpg)\n",
    "\n",
    "图7-7 一个三头的社交媒体分析网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
    "\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# 注意下面我们给输出张量命名了\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Importantly, training such a model requires the ability to specify different loss\n",
    "functions for different \"heads\" of the network: for instance, age prediction is a scalar\n",
    "regression task, but gender prediction is a binary classification task, requiring a different\n",
    "training procedure. However, since gradient descent requires us to minimize a scalar , we\n",
    "must combine these losses into a single value in order to be able to train the model. The\n",
    "simplest way to combine different losses is simply to sum them all. In Keras, you can use\n",
    "either a list or a dictionary of losses in compile to specify different objects for different\n",
    "outputs, and the resulting loss values get summed into a global loss, which is what gets\n",
    "minimized during training.\n",
    "\n",
    "对于上面这样的网络来说，有一个重点在于它需要能够对每个不同的“头”设定不同的损失函数：例如，预测年龄是一个标量回归任务，而预测性别是一个二分分类任务，它们需要不同的训练过程。然而因为梯度下降算法需要能够最小化一个标量，我们必须将这些损失合并成单一值才可以训练模型。最简单的方式是将它们加起来。你可以在Keras中使用一个列表或者字典值作为损失参数传递到模型编译函数中，这样能够简单的将损失值相加，最终使用梯度下降来进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', \n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "\n",
    "# 或者当你指定了输出名称时，可以使用字典值参数\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss={\n",
    "                  'age': 'mse', \n",
    "                  'income': 'categorical_crossentropy',\n",
    "                  'gender': 'binary_crossentropy',\n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that it is also possible to assign different importances to the loss values in their\n",
    "contribution to the final loss. This is useful in particular if the different losses take values\n",
    "on different scales. For instance, the MSE loss used for the age regression task could take\n",
    "a typical value around 3-5, while the crossentropy loss used for the gender classification\n",
    "task could be as low as 0.1. In such a situation, in order to make the contribution of the\n",
    "different losses more balanced, you would assign a weight of 10 to the crossentropy loss,\n",
    "and a weight of 0.25 to the MSE loss. Very imbalanced loss contributions would cause\n",
    "the model representations to be optimized preferentially for the task with the largest\n",
    "individual loss, at the expense of the other tasks.\n",
    "\n",
    "还要知道的是，也可以指定各个损失值的重要程度，也就是各损失对于整体损失的权重。这对于损失值处于不同取值区间的情况下非常有用。例如，用来进行年龄回归的任务使用MSE损失，很可能具有取值范围3-5，而用来进行年龄分类的任务使用交叉熵损失，取值范围很可能低至0.1。在这种情况下为了使得各自对于总体损失的贡献更加平衡，你可以设定交叉熵具有权重10，而MSE具有权重0.25。极度不平均的损失值取值分布可能造成某个特定任务性能得到很大优化，而牺牲了其他任务的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', \n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "              loss_weights=[.25, 1., 10.])\n",
    "\n",
    "# 或者\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss={\n",
    "                  'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy',\n",
    "              }, \n",
    "              loss_weights={\n",
    "                  'age': .25,\n",
    "                  'income': 1.,\n",
    "                  'gender': 10.,\n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Much like in the case of multi-input models, passing Numpy data to the model for\n",
    "training can be done either via a list of arrays or via a dictionary of arrays:\n",
    "\n",
    "正如多输入模型中看到的，可以使用Numpy数组列表或者数组字典的方式将数据传入模型进行训练：\n",
    "\n",
    "译者注：下面代码无法真正运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里假设posts是输入Numpy数组，age_targets, income_targets和gender_targets是对应的目标标记\n",
    "model.fit(posts, [age_targets, income_targets, gender_targets], \n",
    "          epochs=10, batch_size=128)\n",
    "\n",
    "# 或者\n",
    "model.fit(posts, {\n",
    "    'age': age_targets,\n",
    "    'income': income_targets,\n",
    "    'gender': gender_targets,\n",
    "}, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.4 层次的有向无环图\n",
    "\n",
    "> With the functional API, not only can you build models with multiple inputs and multiple\n",
    "outputs, you can also implement networks with a complex internal topology. Neural\n",
    "networks in Keras are allowed to be arbitrary directed acyclic graphs of layers. The\n",
    "qualifier \"acyclic\" is important: these graphs cannot have cycles, i.e. to is impossible for\n",
    "a tensor x to become the input of one of the layers that generated x ). The only processing\n",
    "\"loops\" that are allowed (i.e. recurrent connections) are those internal to recurrent layers.\n",
    "\n",
    "使用函数API不但能够让你构建具有多个输入和多个输出的模型，还能构建具有更加复杂的内部拓扑结构的网络。Keras中可以构建任意有向无环图的神经网络。这里的“无环”是非常重要的：这些图结构当中不能存在循环，也就是说不允许任何产生x张量的层能够接受x作为输入张量。这里唯一能够接受的循环只能处于循环层的内部。\n",
    "\n",
    "> Several common neural network components are implemented as graphs. Two\n",
    "notable ones are Inception modules, and residual connections. To better understand how\n",
    "the functional API can be used to build graphs of layers, let’s take a look at how we can\n",
    "implement both of them in Keras.\n",
    "\n",
    "有一些常见的神经网络组件是使用图实现的。其中两个最著名的就是感知模块和残差连接。为了更好的理解函数API如何构建层次的图模型，我们下面来看看如何在Keras中实现这两个组件。\n",
    "\n",
    "#### 感知模块\n",
    "\n",
    "> Inception is a popular type of network architecture for convolutional neural networks,\n",
    "developed by Christian Szegedy and colleagues at Google in 2013-2014, inspired by the\n",
    "earlier \"network-in-network\" architecture. It consists of a stack of modules which\n",
    "themselves look like small independent networks, split into several parallel branches. The\n",
    "most basic form of an inception module has three to four branches starting with a 1x1\n",
    "convolution, following up with a 3x3 convolution, and ending with the concatenation of\n",
    "the resulting features. This setup helps the network separately learn spatial features and\n",
    "channel-wise features, which is more efficient than learning them jointly. More complex\n",
    "versions of an Inception module are also possible, typically involving pooling operations,\n",
    "different spatial convolution sizes (e.g. 5x5 instead of 3x3 on some branches), and\n",
    "branches without a spatial convolution (only a 1x1 convolution). An example of such a\n",
    "module, taken from Inception V3, is provided in Figure 7.8.\n",
    "\n",
    "感知是卷积神经网络结构中很常见的一种类型，它是有Christian Szegedy和他的谷歌同事在2013-2014年发明的，其原理启发自早期的“网络中的网络”结构。它含有一系列堆叠的层次，令其看起来像一个小型的独立网络，分成多个并行的分支。最基础的感知模块的形式一般有三到四个分支，从一个1x1的卷积层开始，接着一个3x3的卷积层，最终将结果特征级联起来，这样会比顺序的训练得到特征要高效。更复杂的感知模块也存在，可能包含池化操作和不同的空间卷积尺寸（如在一些分支中是5x5而不是3x3的卷积层），以及某些分支不包括空间卷积操作（只含有1x1卷积层）。图7-8展示了这样的一个例子，也就是Inception V3的结构。\n",
    "\n",
    "![inception module](imgs/f7.8.jpg)\n",
    "\n",
    "图7-8 一个感知模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "##### 注：1x1卷积（也称为点卷积）的作用\n",
    "\n",
    "> You already know that convolutions extract spatial patches around every\n",
    "tile in an input tensor, and apply a same transformation to each patch. An\n",
    "edge case is when the patches extracted consist of a single tile. The\n",
    "convolution operation then becomes equivalent to running each tile vector\n",
    "through a Dense layer: it will compute features that mix together\n",
    "information from the channels of the input tensor, but it will not mix\n",
    "information across space at all (since it is looking at one tile at a time).\n",
    "Such 1x1 convolutions are featured in Inception modules, where they\n",
    "contribute to factoring out channel-wise feature learning and space-wise\n",
    "feature learning—a reasonable thing to do if you assume that each\n",
    "channel is highly auto-correlated across space, but different channels\n",
    "might not be highly correlated with each other.\n",
    "\n",
    "你已经了解卷积能够提取输入张量中的每个部分的空间特征，并且在每个局部应用相同的变换。极端情况就是当提取特征的部分仅含有一个像素点。这时候卷积操作就变成了在每个点向量上应用全连接层：它会计算那些输入张量中各点不同通道的特征，而不会计算那些与空间相关的任何特征（因为每次只会观察一个点）。这样的1x1卷积在感知模块中被广泛使用，因为它们能够提供通道特征提取和空间通道相关特征信息，如果假设空间中相同的通道都是高度相关的，而不同的通道却是非高度相关的前提下，这种模型就是非常自然的。\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here is how one would implement the module featured in Figure 7.4 using the\n",
    "functional API:\n",
    "\n",
    "下面是使用函数API实现图7-8的网络的代码：\n",
    "\n",
    "译者注：以下代码无法执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# 下面我们假设已经存在一个4D的张量x\n",
    "\n",
    "# 每个分支的步进都是2，这是必须的，才能使得最终每个分支的输出张量的形状是一致的\n",
    "# 从而能够级联这些结果张量\n",
    "branch_a = layers.Conv2D(128, 1, activation='relu', strides=2)(x)\n",
    "\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
    "\n",
    "branch_c = layers.AvgPooling2D(3, strides=2, activation='relu')(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)\n",
    "\n",
    "# 最后我们级联所有分支的结果张量得到整个模块的输出\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that the full Inception V3 architecture is available in Keras as\n",
    "keras.applications.inception_v3.InceptionV3 , including weights pre-trained on\n",
    "the ImageNet dataset. Another closely related model available as part of the Keras\n",
    "applications module is Xception . \"Xception\", which stands for \"extreme inception\", is a\n",
    "convnet architecture loosely inspired by Inception. It takes the idea of separating the\n",
    "learning of channel-wise and space-wise features to its logical extreme, and replaces\n",
    "Inception modules with depthwise separable convolutions, consisting in a depthwise\n",
    "convolution (a spatial convolution where every input channel is handled separately)\n",
    "followed by a pointwise convolution (i.e. a 1x1 convolution)—effectively, an extreme\n",
    "form of an Inception module, where spatial features and channel-wise features are fully\n",
    "separated. Xception has roughly the same number of parameters of Inception V3, but it\n",
    "shows better runtime performance and higher accuracy on ImageNet as well as other\n",
    "large-scale datasets, due to a more efficient use of model parameters.\n",
    "\n",
    "需要说明的是完整的Inception V3结构可以直接使用Keras内置的`applications.inceptions.inception_v3.InceptionV3`类，并且内置了从ImageNet数据集中预训练的网络权重参数。还有一个很接近的模型同样也内置在Keras当中，就是application里面的Xception模块。“Xception”代表“extreme Inception”，是一个由Inception结构启发得到卷积网络结构。它采用的是彻底分离通道学习和空间学习的方式，将感知模块替换成深度可分离的卷积层，组成一个深度卷积网络（每个输入通道都是分别处理的空间卷积）然后接着一个点卷积层（也就是一个1x1卷积）。简单来说就是感知模块的极端形式，其中的空间特征和通道特征都是完全分离的。Xception模型的参数与Inception V3的参数个数大致相同，但它在ImageNet和其他一些大型数据集上的效率和性能准确率都超过了Inception V3，因为它能够更加有效的使用模型的参数。\n",
    "\n",
    "#### 残差连接\n",
    "\n",
    "> Residual connections are a very common graph-like network component found in many\n",
    "post-2015 network architectures, including Xception. They were introduced by He et al\n",
    "from Microsoft in their winning entry in the ILSVRC ImageNet challenge in late 2015.\n",
    "They tackle two common problems that plague any large-scale deep learning model:\n",
    "vanishing gradients, and representational bottlenecks. In general, adding residual\n",
    "connections to any model that has over ten layers is likely to be beneficial.\n",
    "\n",
    "残差连接是2015年后很流行的图状神经网络结构组件，包括Xception。这个方法是微软的He在2015年底赢得ILSVRC ImageNet挑战比赛的首先提出的。它解决了两个任何大型深度学习模型最主要的问题：梯度消失和表现性瓶颈。通常来说，在任何超过10层的模型上增加残差连接都能够获得更好的结果。\n",
    "\n",
    "> A residual connection simply consist of making the output of an earlier layer\n",
    "available as input to a later layer, effectively creating a shortcut in a sequential network\n",
    "(Figure 7.5). Rather than being concatenated to the later activation, the earlier output is\n",
    "summed with the later activation, which assumes that both activations have the same\n",
    "size. In case of differing sizes, one may use a linear transformation to reshape the earlier\n",
    "activation into the target shape (e.g. a Dense layer without an activation, or for\n",
    "convolutional feature maps, a 1x1 convolution without an activation).\n",
    "\n",
    "一个残差连接组件简单来说就是能够将之前层次的输出作为再后续层次的输入，也就是在序列网络中创建一个短路机制（参见图7-5）。前面层次的输入将会直接加到后续的激活输出中而不是级联起来，因此需要假设两次激活的输出具有相同的形状。在不同形状的情况下，可以使用线性转换将前面层次的输出变成目标形状（例如一个全连接层不带激活函数，或者对于卷积特征地图，一个1x1的卷积不带激活函数）。\n",
    "\n",
    "> Here is how you would implement a residual connection in Keras:\n",
    "\n",
    "下面是使用Keras实现残差连接的代码：\n",
    "\n",
    "译者注：下面的代码无法执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当之前的输入和后续的输出具有相同形状时，使用单位残差连接\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# 这里假设x是一个4D输入张量\n",
    "x = ...\n",
    "\n",
    "# 下面使用一系列的卷积层来提取特征\n",
    "y = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu')(y)\n",
    "\n",
    "# 然后将之前的输入x和y相加\n",
    "y = layers.add([y, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当之前的输入和后续的输出具有不同形状时，使用线性残差连接\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "y = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "# 下面需要使用一个1x1的卷积将x转换成y相同的形状\n",
    "residual = layers.Conv2D(1, strides=2)(x)\n",
    "\n",
    "# 转换后，两者可以进行相加操作\n",
    "y = layers.add([y, residual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "##### 注：深度学习中的表现性瓶颈\n",
    "\n",
    "> In a sequential model, each successive representation layer is built on top\n",
    "of the previous one, which means that it only has access to information\n",
    "contained in the activation of the previous layer. If one layer happens to\n",
    "be too small (e.g. have features that are too low-dimensional), then the\n",
    "model will be constrained by how much information can be crammed into\n",
    "the activations of this layer. You can think of it with a signal processing\n",
    "analogy: if you have an audio processing pipeline that consists of a series\n",
    "of operations that each take as input the output of the previous operation,\n",
    "then if one operation happens to crop your signal to a low frequency\n",
    "range (e.g. 0-15 kHz), the operations downstream will never be able to\n",
    "recover the dropped frequencies. Any loss of information is permanent.\n",
    "Residual connections, by reinjecting earlier information downstream,\n",
    "partially solve this issue for deep learning models.\n",
    "\n",
    "在序列模型中，每个后续的表现层都是基于其上一个层次，这意味着后续层次仅能接触到那些上一层激活后留下来的信息。如果其中一个层次比较小（如仅含有低维度的特征），那么整个模型会被该层激活后能够学习到的信息限制。你可以想象一个信号处理的情景来类比：假设有一个音频处理管道，其中每一步都接受上一步音频输入并输出音频信号，这种情况下如果有一个操作将输入的音频剪裁到了一个低频段（如0-15kHz），那么下游的操作将永远无法恢复那些被裁剪掉的频率。任何信息的损失都是永久的。残差连接将先前的信息重注入到下游操作，能够部分解决深度学习模型的这个问题。\n",
    "\n",
    "------\n",
    "\n",
    "##### 注：深度学习中的梯度消失\n",
    "\n",
    "> Backpropagation, the master algorithm used to train deep neural\n",
    "networks, works by propagating a feedback signal from the output loss\n",
    "down to earlier layers. If this feedback signal has to be propagated\n",
    "through a very deep stack of layers, the signal may become very tenuous\n",
    "or even be lost entirely, rendering the network untrainable—this is the\n",
    "problem of \"vanishing gradients\". This problem occurs both with very\n",
    "deep networks and with recurrent networks over very long sequences—in\n",
    "both cases, a feedback signal must be propagated through a long series\n",
    "of operations. You are already familiar with the solution that the LSTM\n",
    "layer uses to address this problem in recurrent networks: it introduces a\n",
    "\"carry track\" that propagates information in parallel to the main processing\n",
    "track. Residual connections work in a very similar way in feedforward\n",
    "deep networks, but they are even simpler: they introduce a purely linear\n",
    "information carry track parallel to the main layer stack, thus helping to\n",
    "propagate gradients through arbitrarily deep stacks of layers.\n",
    "\n",
    "深度神经网络中的统治算法，反向传播，通过从模型输出的损失值依次回溯信号到网络中各个层次来更新参数。如果这个反馈信号需要反向传播回溯一个非常深的网络，这个信号会发生严重衰减甚至完全小时，结果就是网络变得完全无法训练。这就是常说的“梯度消失”问题。这个问题经常发生在非常深的网络和处理很长序列的循环网络当中。在两种情况中，反馈信号都需要经过很长的步骤操作进行传播。你已经在前面章节中了解了LSTM中解决这个问题的办法：引入一个“传输带”，与主要的处理流并行传递信息。残差连接提供了类似的方案来直接前向传输信息，但更加简单：它提供一个纯粹的线性信息传送带，并行于序列模型，因此能够在任意深度的层次之间直接传输信息。\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.5 层权重共享\n",
    "\n",
    "> One more important feature of the functional API is the ability to reuse a layer instance\n",
    "several time. When you call a layer instance twice, instance of instantiating a new layer\n",
    "for each call, you are reusing the same weights with every call. This allows you to build\n",
    "models that have shared branches—several branches that all share the same knowledge\n",
    "and perform the same operations, i.e. that share the same representations, and learn these\n",
    "representations simultaneously for different sets of inputs.\n",
    "\n",
    "函数API还有一个很重要的特性是它能够多次重用一个层次。每次你重用同一个层实例，你都在使用该层相同的权重值。这可以构建一个具有共享分支的模型，多个分支都共享学习的成果并且采取相同的操作，也就是说，它们共享了相同的表现形式，同时使用不同的输入对这些表现形式进行学习。\n",
    "\n",
    "> One example would be a model that attempts to assess the semantic similarity\n",
    "between two sentences. The model would have two inputs (the two sentences to\n",
    "compare) and would output a score between 0 and 1, where 0 are unrelated sentences and\n",
    "1 are sentences that either identical or mere reformulations of each other. Such a model\n",
    "could be useful in many applications, including de-deduplicating natural language\n",
    "queries in a dialog system.\n",
    "\n",
    "这样的例子可以假设一个模型希望评估两个句子之间的语义相似度。这个模型会有两个输入（两个需要比较的句子）然后输出一个0-1之间的分数，0代表两个句子完全不相关，1代表两个句子完全相同或者只是重新编排了语序。这样的模型可以在很多应用场景中非常有用，包括在一个对话系统中对自然语言进行去重。\n",
    "\n",
    "> Here is how we would implement such a model using layer sharing in the Keras\n",
    "functional API:\n",
    "\n",
    "下面是我们在Keras中实现这个模型的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None, 128)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, None, 128)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 32)           20608       input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           lstm_2[0][0]                     \n",
      "                                                                 lstm_2[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            65          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 20,673\n",
      "Trainable params: 20,673\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 我们只创建一个LSTM层实例\n",
    "lstm = layers.LSTM(32)\n",
    "\n",
    "# 构建左边句子输入的分支\n",
    "# 左边的句子的输入，词向量的长度为128，句子长度不定，然后输入到LSTM层\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "# 构建右边句子输入的分支\n",
    "# 右边句子的输入\n",
    "right_input = Input(shape=(None, 128))\n",
    "# 输入到同一个LSTM层，两个分支共享该层的权重\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "# 下面构建上面的分类器，首先将两个分支输出级联\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "prediction = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model([left_input, right_input], prediction)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Naturally, a layer instance may be used more than once—it can be called arbitrarily\n",
    "many times, reusing the same set of weights every time.\n",
    "\n",
    "当然层实例可以被多次重用，实际上可以重用任意次数，每次都共享其权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.6 模型即层次\n",
    "\n",
    "> Importantly, in the functional API, models can be used as you would use\n",
    "layers—effectively, you may think of a model as a \"bigger layer\". This is true of both the\n",
    "Sequential and Model classes. This means that you can call a model on an input tensor,\n",
    "and retrieve an output tensor:\n",
    "\n",
    "更重要的是，使用函数API可以将模型有效地作为层次来使用，你可以认为一个模型就是一个“大层次”。这对于序列模型来说也是一样的。这意味着你能够使用输入张量调用模型然后获得一个输出张量：\n",
    "\n",
    "```python\n",
    "y = model(x)\n",
    "```\n",
    "\n",
    "> If the model has multiple input tensors and multiple output tensors, it should be called\n",
    "with a list of tensors:\n",
    "\n",
    "如果一个模型有多个输入和多个输出，那可以使用张量的列表来调用：\n",
    "\n",
    "```python\n",
    "y1, y2 = model([x1, x2])\n",
    "```\n",
    "\n",
    "> When you call a model instance, you are reusing the weights of the model—exactly\n",
    "like what happens when you call a layer instance. Simply calling an instance, whether it\n",
    "is a layer instance or a model instance, will always reuse the existing learned\n",
    "representations of the instance—which is quite intuitive.\n",
    "\n",
    "当你调用模型实例时，你就会重用它的权重，正如上面介绍的调用层次实例一样。通过调用实例，不管是层次还是模型实例，都会重用那些学习到的表现形式，这个很容易理解。\n",
    "\n",
    "> One simple practical example of what you can build by reusing a model instance\n",
    "would be a vision model that uses a dual camera as its input: two parallel cameras, a few\n",
    "centimeters (one inch) apart from each other. Such a model could be capable of\n",
    "perceiving depth, which can be useful in many applications. You shouldn’t need two\n",
    "independent models for extracting visual features from the left camera and from the right\n",
    "camera, before merging the two feeds. Such low-level processing can be shared across\n",
    "the two inputs, i.e. done via layers that use the same weights and thus share the same\n",
    "representations. Here is how you would implement this in Keras:\n",
    "\n",
    "作为你构建一个可重用模型实例的简单例子，设想一个视觉模型使用两个摄像头作为它的输入：两个并行的摄像头，之间距离几厘米（一英寸）。这样的模型可以用来检测深度，在实践中可以应用在非常多的场景中。在这个模型中你不应该使用两个独立的模型来提取两个摄像头的视觉特征，然后在合并输出。这种底层的处理模型可以在两个输入之间共享，也就是通过共享层次的权重和相同的表现形式来完成。下面是在Keras中实现的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "# 我们使用Xception作为视觉特征提取的模型，仅使用卷积部分\n",
    "xception_base = Xception(weights=None, include_top=False)\n",
    "\n",
    "# 我们的输入是250x250的图像，然后代入同一个Xception模型实例提取特征\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "left_output = xception_base(left_input)\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "right_output = xception_base(right_input)\n",
    "\n",
    "# 级联输出张量\n",
    "merged = layers.concatenate([left_output, right_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.7 小结\n",
    "\n",
    "> This concludes our introduction to the Keras functional API, an essential tool for building\n",
    "advanced deep neural network architectures. Now you know:\n",
    "\n",
    "> - When to step out of the Sequential API: whenever you need anything more than a\n",
    "linear stack of layers.\n",
    "- How to build Keras models with several inputs, several outputs, and complex internal\n",
    "network topology, using the Keras functional API.\n",
    "- How to reuse the weights of a layer or model across different processing branches, by\n",
    "calling a same layer or model instance several times.\n",
    "\n",
    "本节概要介绍了Keras的函数API，它是用来构建高级深度神经网络结构的重要工具。你应该理解了：\n",
    "\n",
    "- 当你需要任何序列模型无法提供的功能时，你应该去求助于函数API。\n",
    "- 如何使用Keras函数API来构建包括多个输入，多个输出和复杂内在网络拓扑结构的模型。\n",
    "- 如何在不同的分支中重用层次或模型的权重，通过多次调用同一个层次或模型的实例来实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 检查和监测深度学习模型：使用Keras回调和TensorBoard\n",
    "\n",
    "> In this section, we review ways to gain greater access and control over what goes on\n",
    "inside your model during training.\n",
    "\n",
    "在这一节中，我们会深入到模型训练过程中的细节，从而获得更精细的指标和控制。\n",
    "\n",
    "> Launching a training run on a large dataset, for tens of epochs, using model.fit() or\n",
    "model.fit_generator() , can a bit like launching a paper plane: past the initial\n",
    "impulse, you don’t have any control over its trajectory or its landing spot. If you want to\n",
    "avoid bad outcomes (and thus wasted paper planes), it is smarter to use not a paper plane,\n",
    "but a drone that will be able to sense its environment, send data back to its operator, and\n",
    "automatically make stirring decisions based on its current state. The techniques we\n",
    "present here will transform your call to model.fit() from a paper plane into a smart\n",
    "autonomous drone able to self-introspect and dynamically take action.\n",
    "\n",
    "使用`model.fit()`或`model.fit_generator()`（译者注：`fit_generator()`方法已经弃用，统一为`fit()`方法）对大型数据集进行多达数十次迭代的训练，有点像放飞手里的纸飞机：离手之后，你就失去了对它航线和落点的任何控制。如果你希望避免不好的结果（因为这样会浪费纸飞机），更明智的方法是不要使用纸飞机，而是改用能够感知环境的无人机，将它的数据返回给操作者，并且能够自动基于当前状态调整策略。我们本节中介绍的技巧，能够将调用`model.fit()`放飞纸飞机的方式改成放飞智能自动化的无人机，过程中能够自我感知并动态采取措施。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 在训练过程中对模型使用回调\n",
    "\n",
    "> When training a model, there are many things you can’t predict from the start. In\n",
    "particular, you cannot tell how many epochs will be needed to get to an optimal\n",
    "validation loss. In our examples so far, we have always adopted the strategy of training\n",
    "for enough epochs that we would start overfitting, using our first run to figure out the\n",
    "proper number of epochs to train for, then finally launch a new training run from scratch\n",
    "using this optimal number. Of course, this is quite wasteful.\n",
    "\n",
    "当训练模型时，有很多事情是你无法开始预计到的。一个典型例子就是你无法预测多少次迭代后能够达到最优的验证损失。在我们之前的例子中，总是采取训练足够多次迭代并产生过拟合的策略，在我们第一次训练时找到合适的迭代次数，然后使用这个值重新开启一个新的训练。显然这很浪费计算资源。\n",
    "\n",
    "> A much better way to handle this would be stop training when we measure that the\n",
    "validation loss has stopped improving. This can be achieved using a Keras \"callback\". A\n",
    "callback is an object (a class instance implementing specific methods) that is passed to\n",
    "the model in the call to fit and that is called by the model at various points during\n",
    "training. It has access to all the data available about the state of the model and its\n",
    "performance, and it is capable to take action, for instance interrupting training, saving a\n",
    "model, loading a different weight set, or otherwise altering the state of the model.\n",
    "\n",
    "还有一种更好的方式来处理这个问题，就是当我们观察到验证损失不再改善的时候就停止训练。这可以通过Keras的“回调”实现。回调是一个传递给模型训练时候的参数对象（一个实现了特定方法的类实例），并且在训练过程中的某些时间点会被模型调用。它能够获取模型当时的所有状态和性能参数，然后采取某种行动，比方说终止训练过程，保存模型，重新加载不同的权重集，或者直接改变模型的状态值。\n",
    "\n",
    "> Callbacks can be used for:\n",
    "\n",
    "> - Model checkpointing: saving the current weights of the model at different points during\n",
    "training.\n",
    "- Early stopping: interrupting training when the validation loss has stopped improving (and\n",
    "of course, saving the best model obtained during training).\n",
    "- Dynamically adjusting the value of certain parameters during training, such as the\n",
    "learning rate of the optimizer.\n",
    "- Logging the training and validation metrics during training, or visualizing the\n",
    "representations learned by the model as they get updated. In fact, the Keras progress bar\n",
    "that you are familiar with is itself a callback!\n",
    "- And more...\n",
    "\n",
    "回调可以被用在：\n",
    "\n",
    "- 模型状态暂存：在训练的不同时间点保存当前模型的权重。\n",
    "- 提前终止：当验证损失已经停止改善的时候提前终止训练（当然，会保存训练过程中获得的最佳模型）。\n",
    "- 在训练中动态调整模型的某些参数值，例如优化器的学习率。\n",
    "- 在训练过程中记录训练和验证指标，或者可视化模型权重更新后的学习表现形式。事实上，你已经看过很多遍的Keras进度条本身也是一个回调。\n",
    "- 还有很多其他用处......\n",
    "\n",
    "> There are a number of built-in callbacks found in the keras.callbacks module\n",
    "(non-exhaustive list):\n",
    "\n",
    "在`keras.callbacks`模块中有很多内置的回调，下面列出不完全的列表：\n",
    "\n",
    "```python\n",
    "keras.callbacks.ModelCheckpoint\n",
    "keras.callbacks.EarlyStopping\n",
    "keras.callbacks.LearningRateScheduler\n",
    "keras.callbacks.ReduceLROnPlateau\n",
    "keras.callbacks.CSVLogger\n",
    "```\n",
    "\n",
    "> Let’s review a few of them to give you an idea of how to use them:\n",
    "ModelCheckpoint , EarlyStopping , and ReduceLROnPlateau .\n",
    "\n",
    "让我们使用`ModelCheckpoint`，`EarlyStopping`和`ReduceLROnPlateau`作为例子来说明它们的使用方法："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ModelCheckpoint`和`EarlyStopping`回调\n",
    "\n",
    "> You can use the EarlyStopping callback to interrupt training once a target metric being\n",
    "monitored has stopped improving for a fixed number of epochs. For instance, this\n",
    "callback allows you to interrupt training as soon as you start overfitting, thus allowing\n",
    "you to avoid having to retrain your model for a smaller number of epochs. This callback\n",
    "is typically used in combination with ModelCheckpoint , which allows to continually\n",
    "save the model during training (and optionally, to save only the current best model so far,\n",
    "i.e. the version of the model that achieved the best performance at the end of an epoch).\n",
    "\n",
    "你可以在监测的目标指标在固定次数迭代后停止改善的时候，使用`EarlyStopping`回调来终止训练过程。也就是说这个回调能够在发现过拟合出现的情况下提前终止训练，因此避免了你再次使用更小的迭代次数来重新训练的过程。这个回调通常会与`ModelCheckpoint`回调结合使用，该回调能够在训练过程中持续保存模型（或者可以设置为仅保存莫钱为止最佳的模型，也就是在每次迭代结束后仅保存获得最佳性能的模型参数）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "# `model.fit()`接受一个callbacks参数，参数是一个回调函数的列表\n",
    "callbacks_list = [\n",
    "    # EarlyStopping能够提早终止训练，当性能不再改善时\n",
    "    callbacks.EarlyStopping(\n",
    "        # monitor参数设置回调监测的指标，这里设为验证准确率\n",
    "        monitor='acc',\n",
    "        # patience参数设置超过几次迭代不再改善性能时，终止训练\n",
    "        # 这里设置为1次迭代，也就是2次迭代不再改善即终止\n",
    "        patience=1,\n",
    "    ),\n",
    "    # ModelCheckpoint能够在每次迭代后保存模型参数\n",
    "    callbacks.ModelCheckpoint(\n",
    "        # filepath参数设置保存模型参数文件的路径\n",
    "        filepath='my_model.h5',\n",
    "        # 下面两个参数设置每次保存验证损失最低的那个模型参数\n",
    "        # 如果验证损失没有达到更低，则不会覆盖模型参数文件\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 编译和训练模型，以下代码无法执行\n",
    "\n",
    "# 因为在回调中用到了准确率acc，因此它应该处在参数metrics中\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "# 因为在回调中用到了验证损失val_loss，因此训练时必须提供验证集\n",
    "model.fit(x, y, epochs=10, batch_size=32, \n",
    "          callbacks=callbacks_list, validation_data=[x_val, y_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ReduceLROnPlateau`回调\n",
    "\n",
    "> You can use this callback to reduce the learning rate when the validation loss has stopped\n",
    "improving. Reducing or increasing the learning rate in case of a \"loss plateau\" is is an\n",
    "effective strategy to get out of local minima during training.\n",
    "\n",
    "你可以使用这个回调当训练过程中验证损失停止改善时来减小学习率。在出现“损失高原”时，通过减小或者增加学习率可以有效地避免局部最优的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        # monitor设置监测的指标，这里是验证损失\n",
    "        monitor='val_loss',\n",
    "        # factor设置学习率变化的因子，这里将原来的学习率除以10\n",
    "        factor=.1,\n",
    "        # patience设置超过多少个迭代监测指标没改善时应用学习率变化\n",
    "        patience=10,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译和训练模型，以下代码无法执行\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.fit(x, y, epochs=50, batch_size=32, \n",
    "          callbacks=callbacks_list, validation_data=[x_val, y_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义回调\n",
    "\n",
    "> If you need to take any specific action during training that isn’t covered by one of the\n",
    "built-in callbacks, then you should write your own callback.\n",
    "\n",
    "如果你需要一些没有内建回调函数的行为的话，那可以自己编写回调。\n",
    "\n",
    "> Callbacks are implemented by subclassing the class keras.callbacks.Callback .\n",
    "You can then implement any number of the following transparently-named methods,\n",
    "which get called at various points during training:\n",
    "\n",
    "回调通过继承`keras.callbacks.Callback`类来实现。然后根据需要实现下面任意的方法，它们会在训练过程中不同的时间点被调用：\n",
    "\n",
    "```python\n",
    "# 每次迭代开始时调用\n",
    "Callback.on_epoch_begin(logs)\n",
    "# 每次迭代结束时调用\n",
    "Callback.on_epoch_end(logs)\n",
    "\n",
    "# 每个批次开始时调用\n",
    "Callback.on_batch_begin(logs)\n",
    "# 每个批次结束时调用\n",
    "Callback.on_batch_end(logs)\n",
    "\n",
    "# 训练开始时调用\n",
    "Callback.on_train_begin(logs)\n",
    "# 训练结束时调用\n",
    "Callback.on_train_end(logs)\n",
    "```\n",
    "\n",
    "> These methods all get called with a logs argument, a dictionary containing\n",
    "information about what the previous batch, epoch, or training run: training and validation\n",
    "metrics, etc. Additionally, the callback has access to the following attributes:\n",
    "\n",
    "> - self.model , the model instance from which the callback is being called.\n",
    "- self.validation_data , the value of what was passed to fit as validation data.\n",
    "\n",
    "这些方法都使用一个logs参数来调用，这是一个包含前一个批次、迭代或者训练信息的字典值：训练和验证指标等。除此之外回调还有着下面这些额外属性：\n",
    "\n",
    "- `self.model`，这是调用该回调的模型实例\n",
    "- `self.validation_data`，这是传递给训练过程的验证数据\n",
    "\n",
    "> Here is a simple example of a custom callback, where we save to disk (as Numpy\n",
    "arrays) the activations of every layer of the model at the end of every epoch, computed\n",
    "on the first sample of the validation set:\n",
    "\n",
    "下面是一个简单的自定义回调的例子，例子中我们将每个迭代结束时模型中每一层的激活输出（以Numpy数组的形式）保存到磁盘中，该输出是通过验证集的第一个样本计算得到的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class ActivationLogger(callbacks.Callback):\n",
    "    \n",
    "    def set_model(self, model):\n",
    "        # 这个方法是用来提供模型在训练之前对回调进行初始化使用的\n",
    "        \n",
    "        # 设置回调的model属性，用来指定是哪个模型调用的回调\n",
    "        self.model = model\n",
    "        layer_outputs = [layer.output for layer in model.layers]\n",
    "        \n",
    "        # 创建一个新的属性，是返回每层输出的新模型实例\n",
    "        self.activations_model = Model(model.input, layer_outputs)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data is None:\n",
    "            raise RuntimeError(\"Requires validation_data.\")\n",
    "            \n",
    "        # 获得验证集的第一个样本\n",
    "        validation_sample = self.validation_data[0][:1]\n",
    "        # 使用每层输出的模型来计算激活结果\n",
    "        activations = self.activations_model.predict(validation_sample)\n",
    "        \n",
    "        # 保存激活输出结果\n",
    "        with open('activations_at_epoch_' + str(epoch) + '.npz', 'w') as fn:\n",
    "            np.savez(fn, activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is all you need to know about callbacks—the rest is technical details, which can\n",
    "be easily looked up. Now you are equipped to perform any sort of logging or\n",
    "pre-programmed intervention on a Keras model during training.\n",
    "\n",
    "上面就是所有有关回调你需要知道的全部内容了，其他的一些技术细节，都能很容易找到。现在你已经装备了Keras模型训练时能够进行日志记录或预编程干预的工具了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 TensorBoard介绍：TensorFlow可视化框架\n",
    "\n",
    "> To do good research, or develop good models, you need to get rich and frequent feedback\n",
    "about what is going on inside your models during your experiments. That’s the point of\n",
    "running experiments: to get information about how well a model performs—as much\n",
    "information as possible. Making progress is an iterative process, a loop: you start with an\n",
    "idea, then you express it as an experiment, attempting to validate or invalidate your idea.\n",
    "Your run this experiment, then you process the information generated by the experiment.\n",
    "This inspires your next idea. The more iterations of this loop you are able to run, the\n",
    "more refined and powerful your ideas become. Keras helps you go from idea to\n",
    "experiment in the least possible time, and fast GPUs help you get from experiment to\n",
    "result as fast as possible. But what about processing the experiment results? That’s where\n",
    "TensorBoard comes in.\n",
    "\n",
    "要获得好的研究成果，或者发展好的模型，你需要从实验中获取更加丰富和高频的反馈数据，告诉你训练过程中你的模型到底发生了什么。这就是实验的真正目的：获得模型性能的信息，越多越好。你需要在不断的迭代中进步：首先你需要想出一个解决办法，然后将它表示成实验的方式，从而能够验证或者推翻你的这个主意。接下来你就开始运行这个实验，并且处理实验过程中产生的数据。这些数据能够启发你产生改进的方法。这样迭代实验的次数越多，你的方案就会改进的越强大。Keras能够帮助你以最快的速度从设计方案转换为实验，强大的GPU能够帮助你运行实验时最快的获得结果。但处理实验结果的领域就是TensorBoard的舞台了。\n",
    "\n",
    "![deep learning loop](imgs/f7.9.jpg)\n",
    "\n",
    "图7-9 深度学习循环"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In the next few paragraphs, we introduce TensorBoard, a browser-based visualization\n",
    "tool that comes packaged with TensorFlow. Note that it is only available for your Keras\n",
    "models when you are using Keras with the TensorFlow backend.\n",
    "\n",
    "在下面几段内容中，我们会介绍TensorBoard，这是一个基于浏览器的可视化工具，并且随着TensorFlow一起打包。注意TensorBoard仅在你使用TensorFlow作为Keras的后端计算框架时才可用。\n",
    "\n",
    "> The key purpose of TensorBoard is to help you visually monitor everything that goes\n",
    "on inside your model during training. If you are monitoring more information than just\n",
    "the final loss of your model, then you can develop a clearer vision of the model does or\n",
    "doesn’t do, and you can make progress faster. TensorBoard gives you access to several\n",
    "neat features, all inside your browser:\n",
    "\n",
    "> - Visually monitoring your metrics during training.\n",
    "- Visualizing your model architecture.\n",
    "- Visualizing histograms of activations and gradients.\n",
    "- Exploring embeddings in 3D.\n",
    "\n",
    "TensorBoard的主要目标是帮助你对模型训练过程中的所有监控指标进行可视化。如果你在训练中监控了除了模型损失外的更多信息，那么你就能获得模型能力更清晰的认知，并且能够加快上面的循环过程。TensorBoard可以在浏览器中为你提供很多有用的特性：\n",
    "\n",
    "- 可视化监控训练时的指标\n",
    "- 可视化模型结构\n",
    "- 激活输出和梯度的可视化直方图\n",
    "- 在3D中展示嵌入\n",
    "\n",
    "> Let’s demonstrate these features on a simple example. We will be training a 1D\n",
    "convnet on the IMDB sentiment analysis task.\n",
    "\n",
    "让我们使用一个简单的例子来展示这些特性。我们会在IMDB数据集上训练一个1D卷积网络来进行情绪分析。\n",
    "\n",
    "> Below is our model, similar to the one you have seen in the last section of Chapter 6.\n",
    "We only consider the top 2000 words in the IMDB vocabulary, to make word embedding\n",
    "visualization more tractable.\n",
    "\n",
    "下面使我们使用的模型，与第六章最后一节的模型相似。我们只考虑IMDB词汇表中的前2000个单词，这样可以令词嵌入可视化更加容易。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "max_features = 2000 # 仅考虑头2000个特征\n",
    "max_len = 500 # 仅考虑评论中的头500个单词\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length=max_len, name='embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Before we start using TensorBoard, we need to create a directory where we will store\n",
    "log files generated by TensorBoard:\n",
    "\n",
    "在我们使用TensorBoard之前，我们需要创建一个目录来保存TensorBoard生成的日志文件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir ~/my_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let’s launch the training, with a TensorBoard callback instance. This callback will\n",
    "write log events to disk at the specified location.\n",
    "\n",
    "下面让我们使用TensorBoard回调实例来启动训练。这个回调会在指定的目录中写入日志事件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 24s 1ms/sample - loss: 0.7190 - acc: 0.6973 - val_loss: 0.4325 - val_acc: 0.8436\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 23s 1ms/sample - loss: 0.4526 - acc: 0.8600 - val_loss: 0.4776 - val_acc: 0.8626\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 20s 1ms/sample - loss: 0.3940 - acc: 0.8838 - val_loss: 1.6496 - val_acc: 0.7048\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 23s 1ms/sample - loss: 0.3518 - acc: 0.9033 - val_loss: 0.5879 - val_acc: 0.8564\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 0.2812 - acc: 0.9254 - val_loss: 0.6506 - val_acc: 0.8572\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.2571 - acc: 0.9369 - val_loss: 0.6156 - val_acc: 0.8682\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 25s 1ms/sample - loss: 0.2150 - acc: 0.9557 - val_loss: 0.7583 - val_acc: 0.8600\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 24s 1ms/sample - loss: 0.1861 - acc: 0.9668 - val_loss: 0.8180 - val_acc: 0.8676\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 0.1488 - acc: 0.9798 - val_loss: 1.5056 - val_acc: 0.8100\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 23s 1ms/sample - loss: 0.1361 - acc: 0.9833 - val_loss: 0.9213 - val_acc: 0.8668\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 0.1257 - acc: 0.9863 - val_loss: 0.9774 - val_acc: 0.8668\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.1141 - acc: 0.9891 - val_loss: 1.0769 - val_acc: 0.8616\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 0.1079 - acc: 0.9908 - val_loss: 1.1018 - val_acc: 0.8652\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 24s 1ms/sample - loss: 0.1102 - acc: 0.9891 - val_loss: 1.1171 - val_acc: 0.8658\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 23s 1ms/sample - loss: 0.1075 - acc: 0.9910 - val_loss: 1.1555 - val_acc: 0.8680\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 24s 1ms/sample - loss: 0.1123 - acc: 0.9893 - val_loss: 1.1594 - val_acc: 0.8674\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 23s 1ms/sample - loss: 0.1053 - acc: 0.9909 - val_loss: 1.1910 - val_acc: 0.8590\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 0.1040 - acc: 0.9916 - val_loss: 1.2338 - val_acc: 0.8648\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 24s 1ms/sample - loss: 0.1045 - acc: 0.9912 - val_loss: 1.2151 - val_acc: 0.8662\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 24s 1ms/sample - loss: 0.1028 - acc: 0.9921 - val_loss: 1.2925 - val_acc: 0.8616\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import os\n",
    "\n",
    "callbacks = [\n",
    "    TensorBoard(\n",
    "        # 日志存放目录\n",
    "        log_dir=os.path.join(os.environ['HOME'], 'my_log_dir'),\n",
    "        # 每个epoch记录一次激活直方图\n",
    "        histogram_freq=1,\n",
    "        # 每个epoch记录一次嵌入数据\n",
    "        embeddings_freq=1,\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=20, \n",
    "                    batch_size=128, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> At this point, you can launch the TensorBoard server from the command line,\n",
    "instructing it to read the logs the callback is currently writing. The tensorboard utility\n",
    "should have been automatically installed on your machine the moment you installed\n",
    "TensorFlow (e.g. via pip ).\n",
    "\n",
    "现在就能在终端中启动TensorBoard服务了，通过参数指定日志记录所在的目录。tensorboard服务程序应该在你安装TensorFlow的时候就自动安装了（例如通过pip）。\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir=${HOME}/my_log_dir\n",
    "```\n",
    "\n",
    "> You can then browse to localhost:6006 and look at your model training:\n",
    "\n",
    "然后在浏览器打开 localhost:6006 就能查看模型训练过程指标了：\n",
    "\n",
    "![tensorboard](imgs/f7.10.png)\n",
    "\n",
    "图7-10 TensorBoard：指标监控"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Besides live graphs of the training and validation metrics, you get access to the\n",
    "Histograms tab, where you can find pretty visualizations of histograms of activation\n",
    "values taken by your layers:\n",
    "\n",
    "除了实时的训练和验证指标外，你还能查看Histograms标签页，里面可以看到你的层次激活直方图的可视化图像：\n",
    "\n",
    "![histograms](imgs/f7.11.png)\n",
    "\n",
    "图7-11 TensorBoard：激活直方图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The Embeddings tab gives you a way to inspect the embedding locations and spatial\n",
    "relationships of the 10,000 words in our input vocabulary, as learned by our initial\n",
    "Embedding layer. Since the embedding space is actually 128-dimensional, TensorBoard\n",
    "automatically reduces it 2D or 3D using a dimensionality reduction algorithm of your\n",
    "choice: either PCA or T-SNE. Here, in our point cloud, we can clearly see two clusters:\n",
    "words with a positive connotation and words with a negative connotation. The\n",
    "visualization makes it immediately obvious that embeddings trained jointly with a\n",
    "specific objective result in models that are completely specific to the underlying\n",
    "task—that’s the reason why using pre-trained generic word embeddings is rarely a good\n",
    "idea.\n",
    "\n",
    "Projector标签页给出了我们输入词汇表中的2000个单词的嵌入位置和空间关联，也就是第一层嵌入层学习结果。因为嵌入空间实际上是具有128个维度的，因此TensorBoard自动将其降维到了2D或3D空间中，并且可以选择降维算法：比方说PCA或者T-SNE。在这个点云中，我们可以清晰的看到两个聚类：那些具有乐观内涵的单词以及那些具有悲观内涵的单词。这样的可视化显示，用来解决特定任务的模型中的嵌入层训练的结果是非常具有目标导向的，因此通常来说使用预训练的通用词嵌入都不是一个好主意。\n",
    "\n",
    "![embedding](imgs/f7.12.png)\n",
    "\n",
    "图7-12 TensorBoard：词嵌入的3D投影"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The Graphs tab shows an interactive visualization of the graph of low-level\n",
    "TensorFlow operations underlying your Keras model:\n",
    "\n",
    "Graphs标签页展示了这个Keras模型在使用TensorFlow进行运算时的底层操作：\n",
    "\n",
    "![graphs](imgs/f7.13.png)\n",
    "\n",
    "图7-13 TensorBoard：TensorFlow底层运算图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As you can see, there is a lot more going on there than you would expect. The model\n",
    "we just built may look simple when defined in Keras—a small stack of basic layers—but\n",
    "under the hood, we need to construct a fairly complex graph structure to make it work. A\n",
    "lot of it is related to the gradient descent process. This complexity differential between\n",
    "what you see and what you are actually manipulating is precisely the key motivation for\n",
    "using Keras as your way of building models, instead of working with raw TensorFlow to\n",
    "define everything from scratch. Keras makes your workflow dramatically simpler.\n",
    "\n",
    "正如你看到的，TensorBoard还有更多值得研究的特性。上面我们在Keras中定义的模型看起来很简单，就是几个基本层次的堆叠，但在底层，实际上构建了一个相当复杂的图结构才能工作。其中很大一部分与梯度下降过程有关。这种差异正是使用Keras来构建模型的关键原因，从而不需要从头开始使用原始TensorFlow来定义所有东西。Keras能使得工作流极度简化。\n",
    "\n",
    "> Note that Keras also provides another, cleaner way to plot your models, as graphs of\n",
    "layers rather than graphs of TensorFlow ops: the utility keras.utils.plot_model .\n",
    "Using it requires to have installed the Python libraries pydot or pydot-ng , as well as the\n",
    "library graphviz . Let’s take a quick look:\n",
    "\n",
    "还需要说明的是Keras也提供了另一个更加简单干净的方式来绘制模型图，它会直接绘制层次的图而不是TensorFlow底层操作的图，它是`keras.utils.plot_model`工具。要使用这个工具需要安装Python库`pydot`或`pydot-ng`，以及graphviz库。我们来快速过一遍："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "\n",
    "plot_model(model, to_file='imgs/model.png')\n",
    "Image(filename='imgs/model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You also have the option of displaying shape information in the graph of layers:\n",
    "\n",
    "你也可以指定参数用来展示层次的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, show_shapes=True, to_file='imgs/model.png')\n",
    "Image('imgs/model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3 小结\n",
    "\n",
    "> - Keras callbacks provide a simple way to monitor models during training, and\n",
    "automatically take action based on the state of the model.\n",
    "- When using TensorFlow, TensorBoard is a great way to visualize model activity in your\n",
    "browser. You can use it in Keras models via the TensorBoard callback.\n",
    "\n",
    "- Keras回调提供了一个简单的方法来监控训练时的模型情况，并能根据模型的状态自动采取行动。\n",
    "- 当使用TensorFlow的时候，TensorBoard是一个能够在浏览器中可视化模型行为的好工具。你可以在Keras模型中使用TensorBoard回调。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 让模型发挥最大作用\n",
    "\n",
    "> Trying out architectures blindly works well enough if you just need something that works\n",
    "okay. Here we go beyond \"works okay\" into \"works great and wins machine learning\n",
    "competitions\". Here’s a quick explainer on a set of must-know techniques for building\n",
    "state-of-the-art deep learning models.\n",
    "\n",
    "如果只是需要模型工作良好的话，漫无目的地尝试各种结构确实也能够满足要求。本节中我们要超越“工作良好”，变为“工作优异并能赢得机器学习竞赛”。因此我们会介绍一些必须知晓的深度学习模型构建技巧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1 高级结构模式\n",
    "\n",
    "> We’ve already covered one important design pattern in detail in the previous section:\n",
    "residual connections. Here are two more that you should know about. These patterns are\n",
    "especially relevant when building high-performing deep convnets. However, they are\n",
    "commonly found in many other types of architectures as well.\n",
    "\n",
    "在前面的小节中我们已经详细介绍了一个重要的设计模式：残差连接。下面还有两个模式需要了解。这些模式在构建高性能深度卷积网络特别有效。但它们在其他类型结构中也可以看到。\n",
    "\n",
    "#### 批次正规化\n",
    "\n",
    "> \"Normalization\" is a broad category of methods that seek to make different samples seen\n",
    "by a machine learning model more similar to each other, which helps the model learn and\n",
    "generalize well to new data. The most common form of data normalization is one that\n",
    "you have already encountered several times in this book already: centering the data on 0\n",
    "by subtracting the mean from the data, and giving it a unit standard deviation by dividing\n",
    "the data by its standard deviation. In effect, this makes the assumption that the data\n",
    "follows a normal (or Gaussian) distribution, and makes sure that this distribution is\n",
    "centered and scaled to unit variance.\n",
    "\n",
    "“正规化”是一大类广泛使用的手段，用来使得机器学习模型观测到的不同样本尽可能的处于一致的取值范围，这样能够帮助模型更好的学习和增强对新数据的泛化能力。数据的正规化的最通用方式之一是我们在前面已经介绍过的方法：将数据减去其均值从而使得其均值点处于零点，然后将数据除以标准差从而使得新的标准差具有单位标准差。这样做的前提是假设数据符合正态（或高斯）分布，而且分布是按照中心点具有单位偏差延伸的。\n",
    "\n",
    "```python\n",
    "normalized_data = (data - np.mean(data, axis=...)) / np.std(data, axis=...)\n",
    "```\n",
    "\n",
    "> In previous examples, we were only normalizing data before feeding it into our\n",
    "models. However, data normalization should still be a concern after every transformation\n",
    "operated by the network: even if the data coming in a Dense or Conv2D network has\n",
    "0-mean and unit variance, there are no reasons to expect a priori that this will still be the\n",
    "case for the data coming out.\n",
    "\n",
    "在前面的那些例子中，我们仅在数据输入到模型之前进行了正规化。可是当数据在网络中被处理后仍然存在正规化的问题：即使这些数据在传递到全连接层或者Conv2D卷积层时是0均值和单位偏差的情况下，我们依然无法依据先验知识确定这些数据从层次运算得到输出之后依旧保持着正规化。\n",
    "\n",
    "> Batch normalization is a type of layer ( BatchNormalization in Keras) introduced in\n",
    "2015 by Ioffe and Szegedy, capable of adaptively normalizing data even as its mean and\n",
    "variance change over time during training. It works by internally maintaining an\n",
    "exponential moving average of the batch-wise mean and variance of the data seen during\n",
    "training. The main effect of batch normalization is that it helps with gradient\n",
    "propagation—much like residual connections—and thus it allows for deeper networks.\n",
    "Some very deep networks can only be trained if they include multiple\n",
    "BatchNormalization layers. For instance, BatchNormalization is used liberally in\n",
    "many of the advanced convnets architectures that come packaged with Keras, such as\n",
    "ResNet50, InceptionV3 and Xception.\n",
    "\n",
    "批次正规化是一种层（Keras中的`BatchNormalization`），在2015年由Ioffe和Szegedy首先提出，能够自适应地对数据进行正规化，即使在这些数据在训练过程中随时间不断变化着均值和偏差的情况下。它的工作原理是在训练过程中内部维护一个每个批次的均值和偏差的指数平均值。批次正规化的主要效果是它能帮助梯度传播，就像残差连接那样，因此可以允许更深的网络存在。有一些非常深的网络只能在其中有批次正规化层的情况下才能进行训练。例如批次正规化经常使用在很多高级的卷积网络结构中，在Keras内置的一些网络里面也可以看到它，比方说ResNet50，InceptionV3和Xception。\n",
    "\n",
    "> The BatchNormalization layer is typically used after a convolutional or\n",
    "densely-connected layer:\n",
    "\n",
    "批次正规化层通常在卷积层或者全连接层后使用：\n",
    "\n",
    "```python\n",
    "conv_model.add(layers.Conv2D(32, 3, activation='relu'))\n",
    "conv_model.add(layers.BatchNormalization())\n",
    "\n",
    "dense_model.add(layers.Dense(128, activation='relu'))\n",
    "dense_model.add(layers.BatchNormalization())\n",
    "```\n",
    "\n",
    "> The BatchNormalization layer takes an axis argument, which specifies the\n",
    "features axis which should be normalized. This argument defaults to -1 , the last axis in\n",
    "the input tensor. This is the correct value when using Dense layers, Conv1D layers, RNN\n",
    "layers, as well as Conv2D layers with data_format set to \"channels_last\". However, in\n",
    "the niche use case of Conv2D layers with data_format set to \"channels_first\", the\n",
    "features axis is axis number 1 , and the axis argument in BatchNormalization should\n",
    "then be set to 1 accordingly.\n",
    "\n",
    "批次正规化层实例化接受一个axis参数，用来指定应该正规化的特征维度。参数默认值是-1，也就是输入张量的最后一个维度。这个默认值对于全连接层、Conv1D层、RNN层和数据格式是“通道最后”的Conv2D层都是正确的。但是如果在“通道优先”的Conv2D层中，特征维度的值应该为1，所以参数值就应该设置为1.\n",
    "\n",
    "> A recent improvement over regular batch normalization has been \"batch\n",
    "renormalization\", introduced by Ioffe in 2017. It offers clears benefits over batch\n",
    "normalization, at no apparent cost. It is still too early to tell, as I am writing these lines,\n",
    "whether it will come to completely supplant batch normalization—but I would say it is\n",
    "rather likely. Even more recently, Klambauer et al introduced \"self-normalizing neural\n",
    "networks\", which manage to keep data normalized after going through any Dense layer,\n",
    "by using a specific activation function ( selu ) and a specific initializer ( lecun_normal ).\n",
    "This scheme, while highly interesting, is limited to densely-connected networks for now,\n",
    "and its usefulness has not yet been broadly replicated.\n",
    "\n",
    "对常规批次正规化的一个最新的改进是“批次重正规化”，由Ioffe在2017年提出。它提供了相对批次正规化明显的优点，又没有带来明显的损耗。当作者写这本书的时候，还不能确定的说这会完全取代批次正规化，但作者认为这是非常可能的。最近由Klambauer等提出的“自正规化神经网络”，能够提供一种在通过任何全连接层之后都保持数据正规化的方式，它使用了一种特定的激活函数`selu`和一种特定的初始化`lecun_normal`。这个方法，很吸引人，不过还只是限制在全连接网络当中，因此它的作用还需要更加广泛的扩展。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 深度可分卷积\n",
    "\n",
    "> What if I told you that there is a layer you can use as a drop-in replacement for Conv2D ,\n",
    "that will make your model lighter (fewer trainable weight parameters), faster (fewer\n",
    "floating point operations), and perform a few percent better on its task? That is precisely\n",
    "what the depthwise separable convolution layer does ( SeparableConv2D ). A depthwise\n",
    "separable convolution performs a spatial convolution on each channel of its input,\n",
    "independently, before mixing output channels via a \"pointwise\" convolution (a 1x1\n",
    "convolution). This is equivalent to separating the learning of spatial features and the\n",
    "learning of channel-wise features, which makes a lot of sense if you assume that spatial\n",
    "locations in the input are highly correlated, while its different channels are fairly\n",
    "independent. It requires significantly fewer parameters, and involves fewer computations,\n",
    "thus resulting in smaller and speedier models. And because it’s a more representationally\n",
    "efficient way to perform convolution, it tends to learn better representations using less\n",
    "data, resulting in better-performing models.\n",
    "\n",
    "如果我告诉你有一种模型层次，能够用来代替Conv2D，它能使得你的模型更加轻量（更少的可训练权重参数），更加快速（更少的浮点数运算），并且能在同样的任务上获得几个点的性能提升，那就是深度可分卷积层了（`SeparableConv2D`）。一个深度可分卷积会对输入中的每一个通道独立进行空间卷积，然后通过“点卷积”（1x1卷积）将输出通道混合起来。这实际上等同于将空间特征学习和通道特征学习分离，这在假设输入的空间位置是高度相关而不同的通道是相对独立的情况下，是非常有道理的。深度可分卷积需要相对较少的参数，并且涉及更少的计算，因此可以构建一个更小型和快速的模型。因为这是一种更加具有表现性的有效卷积方式，因此深度可分卷积能够使用更少的数据来获得更好的性能。\n",
    "\n",
    "![深度可分卷积](imgs/f7.16.png)\n",
    "\n",
    "图7-16 深度可分卷积：一个独立通道深度卷积然后是一个空间点卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> These advantages become especially important when training small models from\n",
    "scratch on limited data. For instance, here is how you would build a lightweight\n",
    "depthwise separable convnet for an image classification task (softmax categorical\n",
    "classification) on a small dataset:\n",
    "\n",
    "深度可分卷积的这些特性对于从头搭建一个小训练集的小型网络来说是特别重要的。例如，下面就是一个构建轻量深度可分卷积网络来对图像进行分类（softmax分类）的例子，使用了一个小型数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "separable_conv2d_7 (Separabl (None, 298, 398, 32)      196       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_8 (Separabl (None, 296, 396, 64)      2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 148, 198, 64)      0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_9 (Separabl (None, 146, 196, 64)      4736      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_10 (Separab (None, 144, 194, 128)     8896      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 72, 97, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_11 (Separab (None, 70, 95, 64)        9408      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_12 (Separab (None, 68, 93, 128)       8896      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               3300      \n",
      "=================================================================\n",
      "Total params: 41,960\n",
      "Trainable params: 41,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, Dense\n",
    "\n",
    "num_classes = 100\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(SeparableConv2D(32, 3, activation='relu', input_shape=(300, 400, 4)))\n",
    "model.add(SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> When it comes to larger-scale models, depthwise separable convolutions are the basis\n",
    "of the Xception architecture, a high-performing convnet that comes packaged with Keras.\n",
    "You can read more about the theoretical grounding for depthwise separable convolutions\n",
    "and Xception in my paper \"Xception: deep learning with depthwise separable\n",
    "convolutions\" (CVPR 2017).\n",
    "\n",
    "当讨论大型模型时，深度可分卷积是Xception结构的基础组成部分，这是Keras内置的一个强大的卷积网络。你可以通过作者在CVPR 2017上的论文《Xception：使用深度可分卷积的深度学习网络》，来进一步了解深度可分卷积和Xception的原理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2 超参数优化\n",
    "\n",
    "> When building a deep learning model, there are many seemingly arbitrary decisions that\n",
    "you have to make: how many layers should you stack? How many units or filters should\n",
    "go into each layer? Should you use relu as activation, or a different function? Should\n",
    "you use BatchNormalization after a given layer? How much dropout should you use?\n",
    "And so on... These architecture-level parameters are called \"hyperparameters\", to\n",
    "distinguish them from the parameters of a model, which are trained via backpropagation.\n",
    "\n",
    "当构建一个深度学习模型时，存在着很多看起来需要你随机决定的选择：应该使用多少层次来堆叠模型？每个层次需要多少个单元和过滤器？应该使用`relu`还是其他的激活函数？在一个层次后是否需要使用批次正规化？应该使用多少比例的`dropout`？等等等等......这些结构上的参数被称为“超参数”，用于区别在训练过程中通过反向传播更新的普通模型权重参数。\n",
    "\n",
    "> In practice, experienced machine learning engineers and researchers are able to build\n",
    "some intuition over time as to what works and what doesn’t when it comes to these\n",
    "choices—they develop \"hyperparameter tuning\" skills. But there are no formal rules. If\n",
    "you want to get to the very limit of what can be achieved on a given task, you cannot just\n",
    "be content with arbitrary choices made a fallible human. Your initial decisions are almost\n",
    "always suboptimal, even if you have a good intuition. You could refine them by tweaking\n",
    "your choices by hand and retraining your model repeatedly—in fact, that’s what machine\n",
    "learning engineers and researchers spend most of their time on. But it shouldn’t be your\n",
    "job as a human to fiddle with hyperparameters all day—that is better left to a machine.\n",
    "\n",
    "在实践中，有经验的机器学习工程师和研究人员都能够从它们日常的工作培养出哪些参数可能有效或者无效的直觉，也就是说它们发展出了“超参数调优”的技巧。但是这个领域并没有正式的规则。如果你希望在某个特定的任务上获得最佳的性能，那就不能满足于使用随机的选择。通常来说你的第一个选择都不是最优的，即便是你在这个领域已经建立的良好的直觉也一样。几乎所有情况下，你都需要多次重复调整优化参数然后重新训练模型的过程，事实上，这就是机器学习工程师和研究人员消耗时间最多的工作过程。但是这不代表着这种调整超参数的工作应该都是人工完成，而事实上机器协助完成这个任务会更加适合。\n",
    "\n",
    "> Thus, you need to explore the space of possible decisions automatically,\n",
    "systematically, in a principled way. You need to search through architecture space, and\n",
    "find the best performing ones empirically. That’s what the field of automatic\n",
    "hyperparameter optimization is about—it’s an entire field of research, and an important\n",
    "one.\n",
    "\n",
    "因此你需要使用一种正路的方法来自动化系统化的探索参数可能的取值空间。需要搜索结构空间然后凭经验来找到最好性能的那个。这就是自动化超参数优化技术的意义，这是一个相当大的研究领域，也是很重要的一个。\n",
    "\n",
    "> The process of optimizing hyperparameters typically looks like this:\n",
    "\n",
    "> - Pick a set of hyperparameters (automatically).\n",
    "- Build the corresponding model.\n",
    "- Fit it to your training data, and measure the final performance on the validation data.\n",
    "- Pick the next set of hyperparameters to try (automatically).\n",
    "- Repeat. ...\n",
    "- Eventually measure performance on your test data.\n",
    "\n",
    "超参数优化的典型流程如下：\n",
    "\n",
    "- 选择一套超参数（自动化）\n",
    "- 构建相应的模型\n",
    "- 使用训练数据来训练模型，然后使用验证数据来衡量模型的性能\n",
    "- 重新选择一套超参数（自动化）\n",
    "- 重复以上过程\n",
    "- 最终在测试数据上衡量模型的性能\n",
    "\n",
    "> The key to this process is the algorithm that uses this history of validation\n",
    "performance given various sets of hyperparameters to pick the next set of\n",
    "hyperparameters to evaluate. Many different techniques are possible: bayesian\n",
    "optimization, genetic algorithms, simple random search...\n",
    "\n",
    "这个过程中的关键点就是利用给定的不同超参数集的性能记录来计算并选择下一个超参数集的算法。有许多不同可能的技巧：贝叶斯优化，遗传算法，简单随机搜索...\n",
    "\n",
    "> Training the weights of a model is relatively easy: you compute a loss function on a\n",
    "mini-batch of data, then use the backpropagation algorithm to move the weights in the\n",
    "right direction. Updating hyperparameters, on the other hand, is extremely challenging.\n",
    "Indeed, consider that:\n",
    "\n",
    "> - Computing the feedback signal (does this set of hyperparameter lead to a\n",
    "high-performing model on this task?) can be extremely expensive: it requires creating\n",
    "and training a new model from scratch on your dataset.\n",
    "- The hyperparameter space is typically made of discrete decisions, and is thus not\n",
    "continuous, not differentiable. Hence, one typically cannot do gradient descent in\n",
    "hyperparameter space. Instead, one has to rely on gradient-free optimization techniques,\n",
    "which naturally are far less efficient than gradient descent.\n",
    "\n",
    "训练模型的权重相对比较容易：通过模型计算得到一个批次数据的损失函数，然后使用反向传播算法来更新网络权重。然而更新超参数却特别具有挑战性。比如：\n",
    "\n",
    "- 计算反馈信号（这一套超参数是否在这个任务上能获得更优秀的性能？）将会非常昂贵：一次计算需要构建模型并且在数据集上重新训练一次新的模型。\n",
    "- 超参数空间通常是由离散的数值组成的，因此不是连续的，也就是不可微的。所以我们无法在超参数空间中使用梯度下降。这里需要非梯度优化的技巧，这些技巧一般都远没有梯度下降算法效率高。\n",
    "\n",
    "> Because these challenges are hard and the field is still young, we currently only have\n",
    "access to very limited tools to optimize our models. Often, it turns out that random search\n",
    "(picking the hyperparameters to evaluate at random, repeatedly) is the best solution,\n",
    "despite being the most naive one. However, one tool that I have found reliably better than\n",
    "random search is Hyperopt , a Python library for hyperparameter optimization which\n",
    "internally uses trees of Parzen estimators to predict sets of hyperparameters that are likely\n",
    "to work well. Another library called Hyperas integrates Hyperopt for use with Keras\n",
    "models. Do check it out.\n",
    "\n",
    "上述这些挑战都非常困难，且这个领域还很新，我们目前只有很有限的工具可以用来优化我们的模型。通常情况下，随机搜索（重复的随机选取超参数）都是最好的方案，尽管这是一个最简单的算法。但是作者发现有一个工具叫做`Hyperopt`，能可靠地超越随机搜索算法，这是一个Python的库用于超参数优化，其原理是使用树型的Parzen评估器来预测超参数套是否能够改进模型性能。还有一个叫做`Hyperas`的库继承了Hyperopt和Keras模型。都推荐读者去了解一下。\n",
    "\n",
    "> One very important issue to keep in mind when doing automatic hyperparameter\n",
    "optimization at scale, is that of validation set overfitting. Since you are updating your\n",
    "hyperparameters based on a signal that is computed using your validation data, you are\n",
    "effectively training them on the validation data, and thus they will quickly overfit to the\n",
    "validation data. Always keep this in mind.\n",
    "\n",
    "这里有一个非常重要的问题需要说明的是，大规模使用自动化超参数优化时，必须防止验证集过拟合。因为这个过程是通过计算验证数据获得的结果作为信号来更新模型的超参数的，其实相当于你使用了验证数据来训练了你的模型，因此它可能会很快的对验证数据发生过拟合。必须牢记这点。\n",
    "\n",
    "> Overall—hyperparameter optimization is a powerful technique that is an absolute\n",
    "requirement to get to state-of-the-art models on any task, or to win machine learning\n",
    "competitions. Think about it: once upon a time, people would handcraft the features that\n",
    "went into shallow machine learning models. That was very much suboptimal. Now deep\n",
    "learning automates the task of hierarchical feature engineering—features are now learned\n",
    "using a feedback signal, not hand-tuned, and that’s the way it should be. In the very same\n",
    "way, we should not handcraft our model architectures, we should optimize them in a\n",
    "principled way. As I write these lines, the field of automatic hyperparameter optimization\n",
    "is still very young and immature, as deep learning was some years ago, but I would\n",
    "expect it to boom in the next few years.\n",
    "\n",
    "总的说来，超参数优化是你需要在某个任务上得到最优模型或者赢得机器学习竞赛所必须的强大技巧。设想一下，之前人们都是手动选择浅机器学习模型权重参数来拟合数据的特征，这种方法是非优化的。现在的深度学习已经能够自动化这个过程，层次化的权重特征可以从反馈信号中学习得到，而不是手动调整，这才是正确的方式。类似的，我们不应该手动调整模型的结构，而是通过更加正规的方法来学习获得。在做着写这本书的时候，这个超参数优化领域还非常年轻和不成熟，就像深度学习在若干年前那样，但是作者预计它将会在接下来几年中爆发。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.3 模型组装\n",
    "\n",
    "> One last powerful technique for obtain the best possible results on a task is model\n",
    "ensembling . Ensembling consists in pooling together the predictions of a set of different\n",
    "models, in order produce better predictions. If you look at machine learning competitions\n",
    "out there, in particular on Kaggle, in all of them the winners are using very large\n",
    "ensembles of models, which inevitable beat any single model, no matter how good.\n",
    "\n",
    "最后一个获得模型最优性能的强大技巧是模型组装。组装是将一组不同模型的预测汇集在一起，以期获得更好的预测。如果你有观看过机器学习的竞赛，特别是Kaggle，就会发现所有获胜者都大量使用了模型组装，它能碾压单个模型，无论优化程度多少。\n",
    "\n",
    "> Ensembling relies on the assumption that different good models trained independently\n",
    "are likely to be good for different reasons : each model is looking at slightly different\n",
    "aspects of the data to make its predictions, getting hold of part of the \"truth\", but not all\n",
    "of it. You may be familiar with the parable of the blind men and the elephant: an ancient\n",
    "story of a group of blind men who come across an elephant for the first time, and try to\n",
    "understand what the elephant is by touching it. Each man touches a different part of the\n",
    "elephant’s body—just one part, such as the trunk, or a leg. Then the men describe to each\n",
    "other what an elephant is: \"it’s like a snake\", \"like a pillar or a tree\"... These blind men\n",
    "are essentially machine learning models trying to understand the manifold of the training\n",
    "data, each from its own perspective, using its own assumptions (provided by the unique\n",
    "architecture of the model and the unique random weight initialization). Each of them gets\n",
    "part of the truth of the data, but not the whole truth. By pooling their perspectives\n",
    "together, one can get a far more accurate description of the data. The elephant is a\n",
    "combination of parts: not any single blind man gets it quite right, but interviewed\n",
    "together, they can tell a fairly accurate story.\n",
    "\n",
    "组装基于这样一个假设，就是不同优秀的独立训练模型都有着各自优秀的领域：每个模型都观察了数据的不同方面来做出它的预测，因此它们都得到了“真相”的部分，而不是全部。你可能很熟悉盲人摸象的故事：一群盲人都是从来没有接触过大象，然后各自触摸大象身体的不同部位，例如鼻子、腿等，并且通过各自的接触来描述大象。他们对于大象的描述会非常不同：“大象像一条蛇”，“大象像一个树桩”......这些盲人对大象的理解就像机器学习模型对训练数据多样性的理解一样，每个都有着自己的片面观点，使用的是本身的假设（模型具有独特的结构和初始化权重参数）。因此每个模型都只掌握了真相的一部分，而不是全部。如果能够将这些部分汇集在一起，那么就能够得到数据更加准确的描述。大象是一个各部分观察的结合：其中任何一个盲人都没有完全正确的描述它，但是将这些结果组装起来，他们能够获得一个相对准确的描述。\n",
    "\n",
    "> Let’s use classification as an example. The easiest way to pool together the\n",
    "predictions of a set of classifiers (to \"ensemble the classifiers\") is to average their\n",
    "predictions at inference time:\n",
    "\n",
    "如果我们使用分类作为例子。对一组分类器的预测进行聚合（“组装分类器”）的最简单方法就是在推断的时候对它们所有的预测取平均值：\n",
    "\n",
    "```python\n",
    "predict_a = model_a.predict(x_val)\n",
    "predict_b = model_b.predict(x_val)\n",
    "predict_c = model_c.predict(x_val)\n",
    "predict_d = model_d.predict(x_val)\n",
    "\n",
    "# 最终采用均值来作为预测值\n",
    "final_preds = .25 * (predict_a + predict_b + predict_c + predict_d)\n",
    "```\n",
    "\n",
    "> This will only work if the classifiers are more or less equally good. If one of their is\n",
    "significantly worse than the other, then the final predictions may not be as good as the\n",
    "best classifier of the group.\n",
    "\n",
    "这个方法只能在所有的分类器性能基本一致时有效。如果其中有一个分类器的性能明显低于其它的分类器，那得到的最终结果可能还不如其中最优分类器的预测。\n",
    "\n",
    "> A smarter way to ensemble classifiers is to do a weighted average, where the weights\n",
    "are learned on the validation data—typically the better classifiers will be given a higher\n",
    "weight, and the worse classifiers will be given a lower weight. To search for a good set of\n",
    "ensembling weights, one could use random search, or a simple optimization algorithm\n",
    "such as Nelder-Mead.\n",
    "\n",
    "一个更聪明的方法是使用加权平均来聚合所有分类器的预测，这里的权重来自于模型在验证集上的表现，更确切的说，更好的分类器给予更高的权重，而表现不好的分类器给予更低的权重值。要找到这样一组合适的聚合权重值，可以使用随机搜索或例如`Nelder-Mead`这样的简单优化算法。\n",
    "\n",
    "```python\n",
    "predict_a = model_a.predict(x_val)\n",
    "predict_b = model_b.predict(x_val)\n",
    "predict_c = model_c.predict(x_val)\n",
    "predict_d = model_d.predict(x_val)\n",
    "\n",
    "# 下面的权重值是基于优化结果假设得到的\n",
    "final_preds = .5 * predict_a + .25 * predict_b + .1 * predict_c + .15 * predict_d\n",
    "```\n",
    "\n",
    "> There are many possible variants one can imagine: you could do an average of an\n",
    "exponential of the predictions, for instance. In general, a simple weighted average with\n",
    "weights optimized on the validation data provides a very strong baseline.\n",
    "\n",
    "还有很多可能的聚合算法可以考虑：例如可以使用预测的指数平均。在大多数情况下，前面看到的加权平均方法都能提供一个强大的基线准则。\n",
    "\n",
    "> The key to making ensembling work is the diversity of the set of classifiers. Diversity\n",
    "is strength. If all of your blind men had only touched the elephant’s trunk, they would\n",
    "agree that elephants are like snakes, and would forever stay ignorant of the truth of the\n",
    "elephant. Diversity is what makes ensembling work. In machine learning terms, if all of\n",
    "your models are biased in the same way, then your ensemble will retain this same bias. If\n",
    "your models are biased in different ways , the biases will cancel each other out and the\n",
    "ensemble will be more robust and more accurate.\n",
    "\n",
    "模型组装能够成功的关键在于这些分类器的多样性。这里的多样性非常重要。如果所有盲人都知识接触到了大象鼻子，他们都将会同意大象像一条蛇，并且永远无法产生接近真相的描述。因此多样性是使得组装能够提升模型性能的关键因素。在机器学习术语中，如果所有的模型都朝相同方向发生了偏差，那么组装的结果仍然会保留相同的偏差。如果模型能够在不同的方向上发生偏差，那么最终组装的结果能够互相抵消这些偏差，并且使得结果更加的鲁棒和准确。\n",
    "\n",
    "> For this reason, you should be ensembling models that are as good as possible while\n",
    "being as different as possible . This typically means using very different architectures or\n",
    "even different brands of machine learning approaches altogether. One thing that is largely\n",
    "not worth doing, is ensembling a same network trained several times independently, from\n",
    "different random initializations. If the only difference between your models is their\n",
    "random initialization and the order in which they have been exposed to the training data,\n",
    "then your ensemble will be low-diversity and will only provide a tiny improvement over\n",
    "any single model.\n",
    "\n",
    "正因为此，你应该组装那些尽可能不同的模型。这通常表示这些模型使用了完全不同的结构或者完全异质的机器学习算法。这里要说明使用不同的初始化参数在相同的模型上进行多次独立的训练，然后组装到一起这种做法是完全没有必要的。如果用来组装的模型仅在初始化参数和它们观察数据的顺序上有区别，那么这种组装的多样性是很低的，最多仅能提供非常微弱的性能改善。\n",
    "\n",
    "> One thing that I have found to work well in practice—but which does not generalize\n",
    "to every problem domain—is the use of an ensemble of tree-based methods (such as\n",
    "random forests or gradient boosted trees) and deep neural networks. In 2014, partnering\n",
    "with Andrei Kolev, I took the fourth place in the Higgs Boson decay detection challenge\n",
    "on Kaggle using an ensemble of various tree models and deep neural networks.\n",
    "Remarkably, one of the models in the ensemble originated from a quite different method\n",
    "than the others (it was a Regularized Greedy Forest), and had a significantly worse score\n",
    "than the others. Unsurprisingly, it was assigned a small weight in the ensemble. But to\n",
    "my surprise, it turned out to improve the overall ensemble by a large factor, simply\n",
    "because it was so different from every other model: it provided information that the other\n",
    "models did not have access to. That’s precisely the point of ensembling. It’s not so much\n",
    "about how good your best model is, it is about the diversity of your set of candidate\n",
    "models.\n",
    "\n",
    "作者发现了一个实践中模型组装工作的很理想的领域，但是这个方法未必适合所有任务，那就是将树型机器学习方法（例如随机森林或者梯度增强树）和深度神经网络组装起来。作者在2014年与Andrei Kolev合作获得了Kaggle上希格斯玻色子衰减检测竞赛的第四名，使用的正是将不同的树型模型和深度神经网络进行组装的技术。这里需要着重指出的是，用来进行组装的模型中，有一种和其他的区别非常大，作者使用了正则化贪婪森林（RGF），它独立预测的结果远远低于其他模型。不出意外的是，计算最终预测结果时，这个模型的预测被赋予了很小的权重值。但是出乎意料的是，这个模型的加入极大的改进了最终性能，仅仅是因为它与其它模型具有很大的区别：它提供了一些其它模型训练时没有接触到的信息。这就是组装的意义所在。它不在于最佳性能模型表现有多好，而在于这些组装的模型的多样性。\n",
    "\n",
    "> In recent times, one style of basic ensemble that has been very successful in practice\n",
    "is the \"wide and deep\" category of models, blending deep learning with shallow learning,\n",
    "consisting in jointly training a deep neural net with a large linear model. The joint\n",
    "training of a family of diverse models is yet another option to achieve model ensembling.\n",
    "\n",
    "最近出现了一种实践中非常成功的模型组装方式，叫做“宽且深”模型组合，通过混合深度学习和浅学习，然后对一个深度神经网络和一个大型线性模型进行联合训练。联合训练也是另外一类除了模型组装外利用模型多样达到目的的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.4 小结\n",
    "\n",
    "> - When building high-performing deep convnets, you will need to leverage residual\n",
    "connections, batch normalization, and depthwise separable convolutions. In the future, it\n",
    "is likely that depthwise separable convolutions will end up completely replacing regular\n",
    "convolutions, whether for 1D, 2D or 3D applications, due to their higher representational\n",
    "efficiency.\n",
    "- Building deep nets requires making many small hyperparameter and architecture choices,\n",
    "which together define how good your model will end up being. Rather than basing these\n",
    "choices on intuition or random chance, it is better to systematically search through\n",
    "hyperparameter space to find optimal choices. At this time, the process is expensive, and\n",
    "the tools to do it are not very good. But maybe the Hyperopt or Hyperas libraries can help\n",
    "you. When doing hyperparameter optimization, be mindful of validation set overfitting!\n",
    "- Winning machine learning competitions or otherwise obtaining the best best possible\n",
    "results on a task can only be done with large ensembles of models. Ensembling via a\n",
    "well-optimized weighted average is usually good enough. Remember: diversity is\n",
    "strength; it is largely pointless to ensemble very similar models, the best ensembles are\n",
    "set of models that are as dissimilar as possible (while having as much predictive power as\n",
    "possible, naturally).\n",
    "\n",
    "- 当构建高性能深度卷积网络时，你可能需要用到残差连接、批次正规化和深度可分卷积。在将来很可能深度可分卷积会完全取代常规卷积，无论是在1D，2D还是3D场景中，因为它们具有相当高的表现效率。\n",
    "- 构建深度学习模型需要对超参数和结构做出很多选择，这些选择都会影响到模型最终的性能。与其根据直觉或者随机来选择参数，更好的方式是系统性的在超参数空间中进行搜索以获得优化选择。在目前的情况下，这个过程非常昂贵，而且可用的工具也不是特别好。但是也许`Hyperopt`或`Hyperas`库能够对你有一定帮助。当进行超参数优化时，必须注意防止验证集过拟合！\n",
    "- 如果想要赢得竞赛或者榨干所有模型的性能，模型组装是必须的技巧。通过一个优化的权重集来对结果进行组装在大多数情况下都能获得足够优秀的结果。要记住在模型组装中，多样性是关键，组装相似模型的做法是没有必要的，最佳实践是尽可能组装那些完全不同的模型（当然这些模型也应该能够尽量获得最佳的结果）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 总结：高级深度学习最佳实践\n",
    "\n",
    "> In this chapter, you have learned:\n",
    "\n",
    "> - How to build models as arbitrary graphs of layers.\n",
    "- How to reuse layers (\"layer weight sharing\").\n",
    "- How to use models as Python functions (\"model templating\").\n",
    "- How to use Keras callbacks to monitor your models during training and take action based\n",
    "on model state.\n",
    "- How to use TensorBoard to visualize metrics, activation histograms, and even embedding\n",
    "spaces.\n",
    "- What Batch Normalization, Depthwise Separable Convolution, and Residual Connections\n",
    "are.\n",
    "- Why you should use hyperparameter optimization and model ensembling.\n",
    "\n",
    "在本章中，你应该学习到：\n",
    "\n",
    "- 如何构建自定义的图网络\n",
    "- 如何重用层（“层权重共享”）\n",
    "- 如何使用Keras回调来监控模型训练和根据模型状态采取措施\n",
    "- 如何使用TensorBoard来可视化训练指标，激活直方图，甚至是嵌入空间\n",
    "- 什么是批次正规化，深度可分卷积和残差连接\n",
    "- 为什么你需要使用超参数优化和模型组装\n",
    "\n",
    "> With these new tools, you are better equipped to use deep learning in the real world\n",
    "and start building highly competitive deep learning models.\n",
    "\n",
    "有了这些新的工具，你就能够更好的开发实际生活中的深度学习模型，并且能够着手构建具有竞争力的深度学习模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<< [第六章：文本和序列的深度学习](Chapter6_Deep_learning_for_text_and_sequences.ipynb)|| [目录](index.md) || [第八章：生成模型深度学习](Chapter8_Generative_deep_learning.ipynb) >>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda70fb04b0bd9543d0a4d5588de79b26c5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
